name: ML Pipeline Tests with CML Report

on:
  push:
    branches: [ main, dev ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test-ml-pipeline:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      issues: write
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
      
    - name: Set up Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-xdist coverage[toml]
        
    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}
        
    - name: Pull DVC data
      run: |
        dvc pull --force
        
    - name: Install CML
      uses: iterative/setup-cml@v1
      
    - name: Run Tests and Validation
      id: run_scripts
      run: |
        # Run tests and training, but allow the workflow to continue on failure
        # to ensure the report is always generated.
        pytest test_pipeline.py -v --cov=. --cov-report=xml --junit-xml=test-results.xml || echo "Pytest execution failed"
        python -c "from main import Config, IrisPipeline; config = Config(data_path='data/iris.csv'); pipeline = IrisPipeline(config); pipeline.run_training_pipeline()" || echo "Training script execution failed"

    - name: Generate CML Report
      id: cml_report
      env:
        GH_WORKFLOW_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
      run: |
        python -c "
        import os
        import json
        import xml.etree.ElementTree as ET
        from datetime import datetime
        import pandas as pd

        report_parts = []

        # --- Header ---
        report_parts.append('# ğŸš€ ML Pipeline Report')
        report_parts.append(f'A summary of the test, validation, and performance results. [View Workflow Run]({os.environ["GH_WORKFLOW_URL"]})')
        report_parts.append('---')

        # --- Metrics Extraction ---
        tests_passed_str, coverage_str, accuracy_str = 'N/A', 'N/A', 'N/A'
        tests_status, cov_status, acc_status = 'âš ï¸', 'âš ï¸', 'âš ï¸'
        total_tests, failures, errors = 0, 0, 0

        try:
            tree = ET.parse('test-results.xml')
            root = tree.getroot()
            suite = root.find('testsuite') if root.find('testsuite') is not None else root
            total_tests = int(suite.get('tests', 0))
            failures = int(suite.get('failures', 0))
            errors = int(suite.get('errors', 0))
            passed = total_tests - failures - errors
            tests_passed_str = f'{passed} / {total_tests}'
            tests_status = 'âœ…' if failures == 0 and errors == 0 else 'âŒ'
        except (FileNotFoundError, ET.ParseError):
            tests_passed_str = 'XML not found'

        try:
            tree = ET.parse('coverage.xml')
            coverage = float(tree.getroot().get('line-rate')) * 100
            coverage_str = f'{coverage:.1f}%'
            cov_status = 'âœ…' if coverage > 80 else ('âš ï¸' if coverage > 70 else 'âŒ')
        except (FileNotFoundError, ET.ParseError, TypeError):
            coverage_str = 'XML not found'

        try:
            with open('artifacts/metrics.json') as f:
                metrics = json.load(f)
            accuracy = metrics.get('accuracy', 0) * 100
            accuracy_str = f'{accuracy:.2f}%'
            acc_status = 'âœ…' if accuracy >= 90 else ('âš ï¸' if accuracy >= 80 else 'âŒ')
        except (FileNotFoundError, json.JSONDecodeError):
            accuracy_str = 'JSON not found'
            
        # --- Summary Table ---
        report_parts.append('## ğŸ“Š Summary')
        report_parts.append(f'''
        | Status | Metric        | Value          |
        | :----: | :------------ | :------------- |
        | {tests_status} | Tests Passed  | {tests_passed_str}   |
        | {cov_status} | Code Coverage | {coverage_str}   |
        | {acc_status} | Model Accuracy  | {accuracy_str}     |
        ''')
        report_parts.append('---')
        
        # --- Collapsible Details ---
        # Test Results
        report_parts.append('<details><summary>ğŸ”¬ Unit Test Details</summary>')
        if tests_status == 'âœ…':
            report_parts.append(f'\nâœ… **All {total_tests} tests passed successfully!**\n')
        else:
            report_parts.append(f'\nâŒ **{failures} failed, {errors} errors out of {total_tests} tests.** Check the workflow logs for details.\n')
        report_parts.append('</details>')

        # Model Training
        report_parts.append('<details><summary>ğŸ“ˆ Model Training & Validation</summary>')
        try:
            with open('artifacts/metrics.json') as f:
                data = json.load(f)
            table = ['\n#### Performance Metrics', '| Metric | Value |', '|:---|:---|']
            for k, v in data.items():
                table.append(f'| {k.replace("_", " ").title()} | {v:.4f} |')
            report_parts.append('\n'.join(table) + '\n')
        except FileNotFoundError:
            report_parts.append('\nâŒ **Model training failed or metrics file not found.**\n')
        report_parts.append('</details>')

        # Data Quality
        report_parts.append('<details><summary>ğŸ“‹ Data Quality Report</summary>')
        try:
            df = pd.read_csv('data/iris.csv')
            report_parts.append(f'\nâœ… **Data file loaded**: `data/iris.csv`')
            report_parts.append(f'- **Shape**: {df.shape[0]} rows, {df.shape[1]} columns')
            report_parts.append('\n#### Data Preview (first 5 rows)\n```csv')
            report_parts.append(df.head().to_csv(index=False))
            report_parts.append('```\n')
        except FileNotFoundError:
            report_parts.append('\nâŒ **Data file missing**: `data/iris.csv`\n')
        report_parts.append('</details>')

        # --- Footer ---
        report_parts.append('---')
        report_parts.append(f'_Report generated on {datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")}_')
        
        with open('report.md', 'w') as f:
            f.write('\n\n'.join(report_parts))
        "
        
    - name: Publish CML Report
      if: always()
      env:
        REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Creates a comment on the PR or commit.
        cml comment create report.md
        
    - name: Upload test artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results
        path: |
          report.md
          test-results.xml
          coverage.xml
          artifacts/
        retention-days: 30 